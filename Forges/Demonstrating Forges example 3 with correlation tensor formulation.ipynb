{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee89aa2b-56cd-4a4b-b009-e1d346115c65",
   "metadata": {},
   "source": [
    "# Demonstrating Forges example 3 with correlation tensor formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7fb1d-7914-467e-8d45-54f015077aff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Quick summary on my correlation tensor formulation\n",
    "\n",
    "### Correlation tensor\n",
    "- probabilty vector: $P_t \\leftrightarrow P(t)$\n",
    "- correlation tensor: $Q^t_a  \\leftrightarrow Q(a \\mid t)$\n",
    "- Represents any functions (pure or random) mapping from any input sets to output sets.\n",
    "\n",
    "#### Exploitations:\n",
    "- Tensor notations\n",
    "    - Upper index: input\n",
    "    - Lower index: output\n",
    "- Einstein summation:\n",
    "    - $Q^t_a P_t \\leftrightarrow \\sum_t Q(a \\mid t) P(t)$\n",
    "- Not the standard tensor defined as multilinear map from vector space and its dual.\n",
    "    - Correlation tensors are different object as probablity vectors dont form vector space and there aint analouge for basis to speak about basis transformations. (more details on these thoughts i leave it for another article with my idea of Tensors defined over finite feilds)\n",
    "\n",
    "#### Properties:\n",
    "$\\mathbf{1}$ denotes the all one tensor.\n",
    "\n",
    "1. $0 \\leq Q^t_a\\leq 1$ and $\\mathbf{1}^a Q^t_a = \\mathbf{1}^t $\n",
    "- $Q_a = Q^t_a P_t$\n",
    "\n",
    "Convex combibation:\n",
    "- $Q^t_a = Q^{t \\gamma}_a \\Gamma_{\\gamma}$\n",
    "    - $Q^{t \\gamma}_a$ is a row vector of correlation tensors. And $\\mathbf{1}^{\\gamma} \\Gamma_{\\gamma} = 1$\n",
    "    \n",
    "- More clean properties and definitions still trying to concieve, and cant remember the unwritten thoughts now. I leave it from here for another article for now.\n",
    "\n",
    "Function representation:\n",
    "- $Q^t_a$ represents pure (deterministic) function $g: T \\rightarrow A$ if enries are zeros and one. i.e., $Q^t_a \\in \\{0, 1\\}$ satisfying property 1.\n",
    "    - Example: $T = \\{t^1, t^2\\}, A = \\{a^1, a^2\\}$. The function $g:t \\mapsto a \\mid t \\in T, a \\in A$;   $g(t = t^1) = a^1, g(t = t^2) = a^1$ is represented by $Q^{t}_{a}  = \\begin{array}{l|cc}\n",
    " a\\setminus t & t_1 & t_2 \\\\\n",
    "\\hline a_1 &1 & 1 \\\\\n",
    "a_2 & 0 & 0\n",
    "\\end{array}$\n",
    "\n",
    "- $Q^t_a$ represents a random function if its a convex combination of correlation tensors representing pure functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10243485-6b8b-4734-b358-6820d60f060a",
   "metadata": {},
   "source": [
    "### Definition of the general Game:\n",
    "If the players are $[n]$, the types and actions are $T_i$ and $A_i$ for $i \\in [n]$, then \n",
    "\n",
    "- a game is described by a **Payoff Tensor** $v^t_a$, with its components being the payoff profiles, $$v^{[t]}_{[a]} \\in \\mathbb{R}^n$$ where $t \\in T = \\times_i T_i$ and $a \\in A = \\times_i A_i$ are type and action profiles.\n",
    "    - The type profile $t$ occurs at $P_t$\n",
    "- a **Strategy Profile** of the game is the correlation tensor $Q^t_a$.\n",
    "- The **expected payoff** profile of the strategy profile $Q^t_a$ is then $$\\langle v \\rangle = \\mathbf{1}^a (Q^t_a\\circ v^t_a) P_t $$  \n",
    "\n",
    "The strategy profile $Q^t_a$ can be formed out of multiple ways; players individual strategies, due to advices (classical or quantum), intercommunication between players (cheap talks), or further complicate it to any other complex ways humans can think of to make life harder. Thus, this is the most general notion of a static game I can think of.\n",
    "\n",
    "- When all $T_i$'s are singletons, the payoff tensor is a vector, then the game beomes game of complete information.\n",
    "\n",
    "#### Equilibrium\n",
    "\n",
    "The strategy profile $Q^t_a$ is an equilibrium if for every possible deviation $Q^t_a \\rightarrow D^{t}_a(i)$ caused by unilateral deviation of each player $i \\in [n]$, \n",
    "\n",
    "$$\\mathbf{1}^a \\big(Q^t_a\\circ v^t_a(i)\\big) P_t \\geq \\mathbf{1}^a \\big(D^t_a(i)\\circ v^t_a(i)\\big) P_t \\quad \\forall i \\in [n]$$\n",
    "\n",
    "where $v^t_a(i)$ is the payoff tensor corresponding to player $i$, i.e., component of $v^t_a(i)$ is the projection of $v^{[t]}_{[a]} \\in \\mathbb{R}^n$ to player $i$.\n",
    "\n",
    "#### Pareto optimal(attempt)\n",
    "\n",
    "$$\\mathbf{1}^a \\big(Q^t_a\\circ v^t_a\\big) P_t \\geq \\mathbf{1}^a \\big(D^t_a(i)\\circ v^t_a\\big) P_t \\quad \\forall i \\in [n]$$\n",
    "\n",
    "e.i., with the following notation for inequalities of tuples: $(x_i)_i \\geq (y_i)_i \\iff x_i \\geq y_i \\,\\, \\forall i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85c850d-54ed-496e-b66e-be0336a7c582",
   "metadata": {},
   "source": [
    "### The formation of correlation tensor $Q^t_a$\n",
    "\n",
    "#### As from individual player strategies:\n",
    "\n",
    "#### Pure:\n",
    "\n",
    "<!-- player $i$'s: \n",
    " -->\n",
    "Lets denote $Q[A_i^{T_i}]$ as the set of all $Q^{t_1}_{a_1}$ that represents each pure function in $A_i^{T_i}$\n",
    "\n",
    "Example: $T_1 = \\{ 0, 1\\}, A_1 = \\{ 0, 1\\}$. Then $Q[A_i^{T_i}] = \\Big\\{ \\begin{bmatrix}1 & 1 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix} \\Big \\}$ \n",
    "\n",
    "complete Pure strategy profile: $Q^t_a = \\bigotimes_i Q^{t_i}_{a_i}$, where $Q^{t_i}_{a_i} \\in Q(A_i^{T_i}) \\,\\, \\forall i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f369fedd-1bc3-443d-800d-2acbd21d0896",
   "metadata": {},
   "source": [
    "#### Mixed\n",
    "An individual mixed strategy is a convex combination of pure strategies. So, $$Q^{t_i}_{a_i} = Q^{t_i \\gamma_i}_{a_i} \\Gamma_{\\gamma_i} \\, , \\quad \\text{where } Q^{t_i [\\gamma_i]}_{a_i} \\in Q[A_i^{T_i}]$$ \n",
    "\n",
    "Notice: $Q^{t_i \\gamma_i}_{a_i}$ is equvalent to the random function $g(t_i, a_i, \\gamma_i)$\n",
    "\n",
    "Example: let $\\gamma_i \\in \\{1,2,3,4\\}$, $\\Gamma_{\\gamma_i} = \\begin{bmatrix}\n",
    "p_1 \\\\\n",
    "p_2\\\\\n",
    "p_3 \\\\\n",
    "p_3\n",
    "\\end{bmatrix}$, and $Q^{t_i \\gamma_i}_{a_i} = \\begin{bmatrix}\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}& \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}& \\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}& \\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix} \n",
    "\\end{bmatrix}$\n",
    "\n",
    "So, $$Q^{t_i}_{a_i} = Q^{t_i \\gamma_i}_{a_i} \\Gamma_{\\gamma_i} = \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}& \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}& \\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}& \\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix} \n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "p_1 \\\\\n",
    "p_2\\\\\n",
    "p_3 \\\\\n",
    "p_3\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "p_1 + p_2 & p_1 + p_3 \\\\\n",
    "p_3 + p_4 & p_2 + p_4 \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "I denote set of all such mixed strategy tensor that can be formed out of any arbitary $\\Gamma_{\\gamma_i}$ as $Q\\big[\\Delta(A_i^{T_i})\\big]$.\n",
    "\n",
    "complete mixed strategy profile: $Q^t_a = \\bigotimes_i Q^{t_i}_{a_i}$, where $Q^{t_i}_{a_i} \\in Q\\big[\\Delta(A_i^{T_i})\\big] \\,\\, \\forall i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7d61a-2849-42fb-9559-7bb5d69f16dc",
   "metadata": {},
   "source": [
    "<!-- #### General mixed strategy: (i got super silly here, I'm sorry :P. this section beomes irrelavent now)\n",
    "Notice, for the above definition of mixed strategy, each proabibity distribution over $A_i$ for each input in $T_i$ is correlated with each other. A general mixed strategy is any arbitary $Q^{t_i}_{a_i}$. Before I use to define it as a map $\\tilde{g}: T_i \\rightarrow \\Delta A_i$. I denote set of all $Q^{t_i}_{a_i}$ as $Q\\big((\\Delta A_i)^{T_i}\\big)$.\n",
    "\n",
    "Example:\n",
    "$Q^{t_i}_{a_i}  = \\begin{bmatrix}\n",
    "p & q \\\\\n",
    "1-p & 1-q\n",
    "\\end{bmatrix}$ -->\n",
    "\n",
    "So we have, $$Q[A_i^{T_i}] \\subset Q\\big[\\Delta(A_i^{T_i})\\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8678959-9041-433b-9622-b7c15284cd21",
   "metadata": {},
   "source": [
    "#### As from following advice:\n",
    "\n",
    "#### Aumman's pure advice:\n",
    "What we have to keep in mind while formulating is that, it should yeild Aumman's correalted strategy while $T_{i}$s are singletons. The advisor recommends pure strategies.\n",
    "\n",
    "So Aumman's correlated strategy should be a joint distribution over pure strategy profiles $Q[A^{T}] = \\times_i Q[A_i^{T_i}]$. So, \n",
    "\n",
    "$$Q^t_a = Q^{t s}_{a} \\Gamma_{s} \\, , \\quad \\text{where } Q^{t[s]}_{a} \\in Q[A^{T}]$$\n",
    "Expanding: $$Q^t_a = \\bigotimes_i Q^{t_i s_i}_{a_i} \\Gamma_{s_1, s_2, \\dots, s_n} \\, , \\quad \\text{where } Q^{t_i}_{a_i} \\in Q[A_i^{T_i}] \\,\\, \\forall i$$\n",
    "\n",
    "I denote the set of all such $Q^t_a$ formed out of any arbitary $\\Gamma_{s}$ as $Q\\big[\\Delta(A^{T})\\big]$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b21115-7e93-4f53-85d5-28f1160945d6",
   "metadata": {},
   "source": [
    "#### Mixed strategy advice:\n",
    "\n",
    "In game of complete information, recommending mixed strategies is same as recomending a pure strategies from a different distribution. Does this fact hold here as well? Lets check it out!\n",
    "\n",
    "So I denote set of all mixed strategy profiles as $Q\\big[\\Delta^n (A^{T}) \\big] = \\times_i Q \\big[\\Delta(A_i^{T_i})\\big]$ \n",
    "\n",
    "So the correlation tensor now is, $$Q^t_a = Q^{t s}_{a} \\Gamma_{s} \\, , \\quad \\text{where } Q^{t[s]}_{a} \\in Q\\big[\\Delta^n (A^{T}) \\big]$$\n",
    "\n",
    "And I denote the set of all such $Q^t_a$ formed out of any arbitary $\\Gamma_{s}$ as $Q\\Big[\\Delta\\big(\\Delta^n (A^{T})\\big)\\Big]$\n",
    "\n",
    "Now exapanding $$Q^t_a = \\bigotimes_i Q^{t_i s_i}_{a} \\Gamma_{s} = \\bigotimes_i Q^{t_i \\gamma_i s_i}_{a_i} \\Gamma_{\\gamma_i} \\Gamma_{s} \\quad \\text{where } Q^{t_i [\\gamma_i, s_i]}_{a_i} \\in Q[A_i^{T_i}]$$\n",
    "\n",
    "$$= Q^{t \\gamma s}_{a} \\Gamma_{\\gamma} \\Gamma_{s} =  Q^{t \\gamma s}_{a} \\Gamma_{\\gamma s} = Q^{t (\\gamma,s)}_{a} \\Gamma_{(\\gamma, s)}$$\n",
    "\n",
    "Now, $Q^{t [(\\gamma,s)]}_{a} \\in Q[A^{T}]$ as $Q^{t_i [(\\gamma_i, s_i)]}_{a_i} \\in Q[A_i^{T_i}]$. Thus, we have proved its the same case here as well.\n",
    "\n",
    "So, we have the equevalence $$Q\\Big[\\Delta\\big(\\Delta^n (A^{T})\\big)\\Big] = Q\\big[\\Delta(A^{T})\\big]$$\n",
    "\n",
    "Me: *And there you witness the first power of my correlation tensor formulation!* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da061ec-8d85-43d7-b206-c26363ad316c",
   "metadata": {},
   "source": [
    "<!-- #### The General correlated strategy\n",
    "\n",
    "The above equivalence is not true for the general mixed strategy, $Q\\big((\\Delta A_i)^{T_i}\\big) \\setminus  Q\\big(\\Delta(A_i^{T_i})\\big)$,  where $Q^{t_i}_{a_i}$ cannot be decomposed into convex combination of pure strategies. Thus, advice of a general mixed strategy becomes **relavent** in games of incomplete information! \n",
    "\n",
    "So I denote set of all general mixed strategy profiles as $Q\\big((\\Delta^n A)^{T} \\big) = \\times_i Q \\big((\\Delta A_i)^{T_i}\\big)$ \n",
    "\n",
    "So the correlation tensor now is, $$Q^t_a = Q^{t s}_{a} \\Gamma_{s} \\, , \\quad \\text{where } Q^{t(s)}_{a} \\in Q\\big((\\Delta^n A)^{T} \\big)$$\n",
    "\n",
    "And I denote the set of all such $Q^t_a$ formed out of any arbitary $\\Gamma_{s}$ as $Q\\Big(\\Delta\\big((\\Delta^n A)^{T}\\big)\\Big)$. And you may call this as the \"Local correlation\".\n",
    "\n",
    "So we have, $$Q\\Big(\\Delta\\big(\\Delta^n (A^{T})\\big)\\Big) = Q\\big(\\Delta(A^{T})\\big) \\subset Q\\Big(\\Delta\\big((\\Delta^n A)^{T}\\big)\\Big)$$\n",
    "\n",
    "**Finally, there we see the super leap from Aumman's concept in games of complete information!**  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd73e4c-e083-4435-9006-8e5847fdc3a4",
   "metadata": {},
   "source": [
    "#### Quantum advice:\n",
    "\n",
    "$$Q^t_a = \\operatorname{Tr} \\rho M^{[t]}_{[a]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6358276c-4084-4a39-aee4-569dc6d4b51d",
   "metadata": {},
   "source": [
    "#### Communicated advice\n",
    "\n",
    "If the advisor takes inputs ($r$) from players to implement distribution over advice, then\n",
    "$$Q^t_a = \\bigotimes_i Q^{s_i}_{a_i} Q^r_s \\bigotimes_i Q^{t_i}_{r_i} $$\n",
    "\n",
    "If the adviser advices full function $Q^{t_i}_{a_i}$ based on input communicated by the players:\n",
    "$$Q^t_a = \\bigotimes_i Q^{t_i s_i}_{a_i} Q^r_s \\bigotimes_i Q^{t_i}_{r_i} P_t$$\n",
    "\n",
    "In Auletta, the player randomizes strategy functions $f_i$ and $g_i$ with the same random variable $\\lambda_i$. In terms of correlation tensor, this can be generalized as a convex compination of the joint correlation tensor that represent both, $Q^{t_i s_i t_i \\lambda_i}_{a_i r_i} \\Gamma_{\\lambda_i}$. So,\n",
    "\n",
    "$$Q^t_a = \\bigotimes_i Q^{t_i s_i t_i \\lambda_i}_{a_i r_i} \\Gamma_{\\lambda_i} Q^r_s P_t$$ \n",
    "\n",
    "The interesting issue here is that $Q^{t_i s_i t_i \\lambda_i}_{a_i r_i}$ cannot be strictly correlated as player sending input $r_i$ to communication device, and processing the output $s_i$ to act on $a_i$ are two seperate events in time! so it should be a product correlation tensor.\n",
    "\n",
    "<!-- If $Q^{t_i s_i t_i}_{a_i r_i}$ is a general mixed map or a noisy channel, then the most general strategy profile $Q^t_a$ is formed by: \n",
    "\n",
    "$$Q^t_a = \\bigotimes_i Q^{t_i s_i t_i }_{a_i r_i} Q^r_s P_t$$  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee041d-c855-4fce-b872-5c5dbae9fd9a",
   "metadata": {},
   "source": [
    "## The agent normal form:\n",
    "\n",
    "In Forges, the agents normal form is a conversion of game of incomplete information to complete information like so,\n",
    "$$v^t_a \\longrightarrow v_{a,t} P_t$$\n",
    "\n",
    "**Alternate Interpretation of the same form** \n",
    "\n",
    "The advicer to the boy: *\"I do not wish to know your current **type** of emotion so dont tell me. But, if you are **sad**, then go and have a **nap**. And if you are **happy**, then go and **play in the rain** \"*\n",
    "\n",
    "But, thats just a normal advice of a pure strategy (function mapping from types to actions). And it's **not** an advice of agent normal form!\n",
    "\n",
    "So here's the **correct** advice that mimics this form:\n",
    "\n",
    "The advicer to the boy: *\"So dont tell me your current **type** of emotion. But, if you are **sad**, then go and have a **nap**. And if you are ...\"*\n",
    "\n",
    "Meanwhile the advicer tosses a coin, finds \"Heads\"!. And then,\n",
    "\n",
    "the advicer contineus to the boy: *\"so yeah.. and if you are **happy**, then go and **play in the rain** \"*.\n",
    "\n",
    "Already having been found \"heads\" on the toss,\n",
    "\n",
    "the advicer to Thor (the god of thunder): \"**strike the lightning on the playground!**\"\n",
    "\n",
    "\n",
    "And now this might give you the right idea!... The advicer is the \"decieving Devil\". Ofcourse, the idea of alteranate way of veiwing an advice in a baysian game that is in its agent normal form. And this may or may not be in the  covex combitnation of pure or mixed strategy profiles (function tuples).\n",
    "\n",
    " \n",
    "<!-- - But notice $A_i$ is now an element of the power set of $A_{t_i} = \\{a_{(i, t_i)} | t_i \\in T_i, \\,\\, a_{(i, t_i)} \\in A_i\\}$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cfb661-fb6e-4370-9e6f-2154d3bc78ca",
   "metadata": {},
   "source": [
    "#### Strategy:\n",
    "\n",
    "- I denote an agent to player $i$ as $i_{t_i}$, and  the action of the agent as $a_{i_{t_i}} \\in A_i$.\n",
    "- In agent normal form, the advicer correlates the advice to the active agent of each players. And the active agents from each players $i_{t} = (i_{t_i})_{i} = (1_{t_1}, 2_{t_2}, \\dots, n_{t_n})$ is activated by $P(t)$.\n",
    "    - I denote the active agents action profile as $a_{i_t} = (a_{1_{t_1}}, a_{2_{t_2}}, \\dots, a_{n_{t_n}})$ \n",
    "\n",
    "- As per my interpretation (the alternate view I described above) of Forges, the advicer **do not** know the current active agent profile. However, the adviser has already prepared the joined advices for **each** active agent profiles, and privtely recommends agent actions $a_{i_{t_i}}$ of all agents $i_{t_i}$ of player $i$ to the player $i$, without asking the player $i$ which of it's agent is currently active. \n",
    "    - In this way, the adviser **do not** know the current active agent profile $i_{t}$ activated by $P(t)$. So the adviser is still not God and also doesnt gets inputs from players.\n",
    "    - Neigther, the each player know the current active agents of other players than their self's. And as usual the players only knows the distribtion $P$ which they can use to calculate conditional probabilty of other players active agents.\n",
    "    - **Thus the game is still bayesian and played as game of incomplete information**\n",
    "\n",
    "- So the correlation tensor for active agent profile due to advice is as follows:\n",
    "$$Q_{a_{i_t}} = \\bigotimes_{i} Q^{s_{i_{t_i}}}_{a_{i_{t_i}}} \\Gamma_{s_{i_{t}}}$$\n",
    "\n",
    "**But there's a huge ambuigity that arises here!! A PLAYER MAY RECIEVE MORE THAN TWO ADVISES FOR A SAME AGENT AT THE SAME TIME!** \n",
    "\n",
    "**However that can be FIXED! With the following imposition** (spoiler alert: this fixation is what causes the agent normal form strategy to always be Local):\n",
    "\n",
    " -- work is under progress for this general method. I suggest you to jump to below section were I demonstrate a simple example --\n",
    "\n",
    "If the adviser chooses to correlate within the agent profile $(i_{t_i}, -i_{t_{-i}}) \\equiv (1_{t_1}, 2_{t_2}, \\dots, i_{t_i}, \\dots, n_{t_n}) $, then the advicer cannot correlate within the following agent profiles: \n",
    "$$(i_{t_i}, -i_{t^{\\prime}_{-i}}) \\quad \\forall t^{\\prime}_{-i} \\neq t_{-i}$$.\n",
    "\n",
    "And this **must** be the case for all agents $i_{t_i}$ of every player $i \\in [n]$. And in this way, all agents will get only **one** advice. And for those agent profiles that are not correlated, their distribution can be formed by taking the marginals for each agents from the correlated profiles, and then taking their product.\n",
    "\n",
    "Now this gets very tricky when we are speaking of general multiplayer game with distinct number of types for each players. So in general case, I take the player with maximum number of types and label that player as $i = m$. Then I'll have to proceed with respect to this player. So for each  \n",
    "\n",
    "\n",
    "\n",
    "- As I interpreted above, this form can still be played as game of incomplete informatiom. So we can have this following transformation:\n",
    "$$Q_{a_{i_t}} v_{a_{i_t}} P_t \\longrightarrow Q^t_a v^t_a$$\n",
    "    - This means we can stack up $Q_{a_{i_t}}$'s column wise by $t$ to form the correlation tensor like so: $$Q^t_a = \\begin{bmatrix}Q_{a_{i_t}}\\end{bmatrix}^t$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1995312a-0e5b-4158-864c-ac0f8743a53b",
   "metadata": {},
   "source": [
    "### General agent form.\n",
    "\n",
    "The advicer can prepare the agent normal form advice in multiple ways. So the advicer can now randomize this space and draw one of the method from a probablity distribution over it. So if $\\Gamma_{\\alpha}$ is such probablity distribution and $Q^{t[\\alpha]}_a$'s are all the correlation tensors formed from these distinct multiple agent normal form advices, then the final correlation tensor would be: $$Q^{t\\alpha}_a \\Gamma_{\\alpha}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef6fb08-3e45-44f1-ae5a-e0c1b9d1cea8",
   "metadata": {},
   "source": [
    "#### simple Example demonstrating my interpretaion of agent normal form:\n",
    "$T_1 =\\{0, 1\\}, A_1 =\\{0, 1\\}$ and $T_2 =\\{0\\}, A_2 =\\{0, 1\\}$ \n",
    "\n",
    "So in this game there are two ways to implement an agent normal form advice. The advicer can choose to correlate $(1_0, 2_0)$ and $(1_1)$ (if player 2 had two types, then it would had been $(1_1, 2_1)$) and not correlate $(1_1, 2_0)$, or, correlate $(1_1, 2_0)$ and $(1_0)$ and not correlate $(1_0, 2_0)$ .\n",
    "\n",
    "1. Correlate $(1_0, 2_0)$ and $(1_1)$, and not correlate $(1_1, 2_0)$:\n",
    "\n",
    "let $\\Gamma_{s_{1_0}, s_{2_0}} = \\begin{array}{l|cc}\n",
    " s_{1_0}, s_{2_0}\\backslash & &  \\\\\n",
    "\\hline    \\quad 00 & p_1 \\\\\n",
    "          \\quad 01 & p_2 \\\\\n",
    "          \\quad 10 & p_3 \\\\\n",
    "          \\quad 11 & p_4 \n",
    "        \\end{array} \\quad \\Gamma_{s_{1_1}} = \\begin{array}{l|cc}\n",
    " s_{1_1}\\backslash & &  \\\\\n",
    "\\hline    \\quad 0 & p_1^1 \\\\\n",
    "          \\quad 1 & p_2^1 \\\\ \n",
    "        \\end{array}$\n",
    "        \n",
    "     \n",
    "        \n",
    "        \n",
    "\n",
    "$$Q^{[0 0]}_a = Q_{a_{1_0}, a_{2_0}} =  Q^{s_{1_0}}_{a_{1_0}} Q^{s_{2_0}}_{a_{2_0}} \\Gamma_{s_{1_0}, s_{2_0}} = \\begin{bmatrix}\n",
    "p_1 \\\\\n",
    "p_2\\\\\n",
    "p_3 \\\\\n",
    "p_4\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "so $$Q^{[1 0]}_a = Q_{a_{1_1}, a_{2_0}} = Q^{s_{1_1}}_{a_{1_1}} Q^{s_{2_0}}_{a_{2_0}}  \\Gamma_{s_{1_1}} \\Gamma_{s_{1_0}, s_{2_0}} \\mathbf{1}^{s_{1_0}} = \\begin{bmatrix}\n",
    "p_1^1(p_1+p_3) \\\\\n",
    "p_1^1(p_2 +p_4) \\\\\n",
    "p_2^1(p_1+p_3) \\\\\n",
    "p_2^1(p_2 +p_4)\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "so $Q^t_a = \\begin{bmatrix}\n",
    "Q^{[0 0]}_a & Q^{[1 0]}_a\n",
    "\\end{bmatrix} = \\begin{array}{l|cc}\n",
    " a_1 a_2\\backslash t_1 t_2 & 00 & 10  \\\\\n",
    "\\hline    \\quad 00 & p_1 & p_1^1(p_1+p_3) \\\\\n",
    "          \\quad 01 & p_2 & p_1^1(p_2 +p_4)  \\\\\n",
    "          \\quad 10 & p_3 & p_2^1(p_1+p_3) \\\\\n",
    "          \\quad 11 & p_4 & p_2^1(p_2 +p_4) \n",
    "        \\end{array}$\n",
    "        \n",
    "The extremal points belongs to $Q\\big[A_1^{T_1}A_2^{T_2}\\big]$. So this belongs to local correlation class.\n",
    "        \n",
    "2. Correlate $(1_1, 2_0)$ and $(1_0)$, and not correlate $(1_0, 2_0)$:        \n",
    "\n",
    "similiarly, for this strategy we get: \n",
    "\n",
    "$Q^t_a = \\begin{array}{l|cc}\n",
    " a_1 a_2\\backslash t_1 t_2 & 00 & 10  \\\\\n",
    "\\hline    \\quad 00 & q_1^0(q_1+q_3) & q_1\\\\\n",
    "          \\quad 01 & q_1^0(q_2 +q_4)& q_2  \\\\\n",
    "          \\quad 10 & q_2^0(q_1+q_3) & q_3\\\\\n",
    "          \\quad 11 & q_2^0(q_2 +q_4)& q_4 \n",
    "        \\end{array}$\n",
    "\n",
    "And a general agent form should be convex combination of both:\n",
    "\n",
    "$Q^t_a = \\begin{array}{l|cc}\n",
    " a_1 a_2\\backslash t_1 t_2 & 00 & 10  \\\\\n",
    "\\hline    \\quad 00 & \\alpha_1 p_1 + \\alpha_2  q_1^0(q_1+q_3) &\\alpha_1 p_1^1(p_1+p_3) + \\alpha_2  q_1\\\\\n",
    "          \\quad 01 & \\alpha_1 p_2 + \\alpha_2 q_1^0(q_2 +q_4)& \\alpha_1p_1^1(p_2 +p_4) + \\alpha_2  q_2  \\\\\n",
    "          \\quad 10 & \\alpha_1 p_3 + \\alpha_2 q_2^0(q_1+q_3) & \\alpha_1p_2^1(p_1+p_3) +  \\alpha_2 q_3\\\\\n",
    "          \\quad 11 & \\alpha_1 p_4 + \\alpha_2 q_2^0(q_2 +q_4)& \\alpha_1p_2^1(p_2 +p_4) + \\alpha_2  q_4 \n",
    "        \\end{array}$\n",
    "        \n",
    "where $\\alpha_1 + \\alpha_2 = 1$ and $\\alpha_1, \\alpha_2 \\geq 0$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e19aa5-e100-4f5d-9889-ecff3bedb669",
   "metadata": {},
   "source": [
    "# The forges example 3 game\n",
    "\n",
    "$T_1 = \\{0, 1\\}, T_2 = \\{0\\}$, $P(t) = \\frac{1}{2} \\,\\, \\forall t \\in T$ (uniform), $A_1 = \\{0,1\\}, A_2 = \\{0,1,2\\}$.\n",
    "\n",
    "#### payoff tensor:\n",
    "\n",
    "$v^a_t =$\n",
    "\n",
    "|**a \\ t**|**00**|**10**|\n",
    "|-------|-----|-----|\n",
    "|**00** |(6,0)|(0,6)|\n",
    "|**01** |(0,4)|(6,4)|\n",
    "|**02** |(4,6)|(4,0)|\n",
    "|**10** |(6,0)|(0,6)|\n",
    "|**11** |(0,4)|(6,4)|\n",
    "|**12** |(4,6)|(4,0)|\n",
    "\n",
    "**Notice:** The payoffs are independent of $A_1$ here also.\n",
    "\n",
    "### The game description:\n",
    "- Here, player 1 sends $a_1 \\in A_1$ to player 2.\n",
    "- So, player 2 takes $a_1$ as input.\n",
    "    - Notice there are no other external inputs for player 2 as $T_2$ is singleton.\n",
    "- Since $v^t_a$ is independent of $a_1$, player 1's strategy only is to use it to unfluence player 2's decision on $a_2$, which $v^a_t$ is depndent on.\n",
    "- As player 1 sends $a_1$ based on $t_1$, player 2's strategy is now to choose $a_2$ based on $a_1$, as $v^a_t$ is dependent on $t_1$.\n",
    "\n",
    "#### strategies:\n",
    "\n",
    "so the pure strategy set for player 1 is $A_1^{T_1}$ and for player 2 is $A_2^{A_1}$\n",
    "\n",
    "Individual strategy(mixed or pure) with stochastic tensor notation:\n",
    "\n",
    "player 1: $Q^{t_1}_{a_1 a_1} \\quad$,   player 2: $Q^{a_1}_{a_2}$\n",
    "\n",
    "So $$\\begin{equation}Q^t_a = Q^{t_1,0}_{a_1,a_2} = Q^{t_1}_{a_1 a_1} Q^{a_1}_{a_2}\\end{equation}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185858b-9b8f-4822-9769-9680992b0866",
   "metadata": {},
   "source": [
    "### Agent normal form:\n",
    "\n",
    "so Agents for player $1$ are: agent $1_0$ and agent $1_1$. \n",
    "\n",
    "Since the $T_2$ is singleton, the active agent profiles is: $i_t = \\{(1_0, 2_0), (1_1, 2_0)\\}$\n",
    "\n",
    "#### Advice for $(1_1, 2_0)$:\n",
    "\n",
    "Let suggestion signals for agent $(1_1, 2_0)$ denote $s_{1_1} = \\{0,1\\}$ and $s_{2_0} = \\{0,1\\}$.\n",
    "\n",
    "So the probability vector formed out of advice should be,\n",
    "\n",
    "<!-- \\begin{equation*}\n",
    "q(a_{1_1}, a_{2_0}) =  q(a_{1_1} \\mid s_{1_1}) \\alpha_2(a_{1_1}, s_{2_0}}) q{s_{1_1}}_{a_{1_1}} \\Gamma_{s_{1_1} s_{2_0} s_{1_1}} \n",
    "\\end{equation*} -->\n",
    "\n",
    "$$Q_{a_{1_1}, a_{2_0}} = Q^{s_{1_1}}_{a_{1_1}} Q^{a_{1_1} s_{2_0}}_{a_{2_0}} Q^{s_{1_1}}_{a_{1_1}} \\Gamma_{s_{1_1} s_{2_0} s_{1_1}} \\tag{1}$$\n",
    "\n",
    "**for agent $1_1$:**\n",
    "\n",
    "$Q^{s_{1_1}}_{a_{1_1}}  = \\begin{array}{l|cc}\n",
    "a_{1_1}\\backslash s_{1_1} & 0 & 1  \\\\\n",
    "\\hline    \\quad 0 & 1 & 0 \\\\\n",
    "          \\quad 1 & 0 & 1 \n",
    "        \\end{array} =  \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "**for agent $2_0$:**\n",
    "\n",
    "notation in forges: \n",
    "\n",
    "$\\alpha_2: A_1 \\longrightarrow A_2$.\n",
    "\n",
    "Dont forget, here $A_1 = \\{0,1\\}, A_2 = \\{0,1,2\\}$ \n",
    "\n",
    "suggestion for 1st signal $[s_{2_0} = 0]$:   $\\alpha_{2}(0) = 1, \\alpha_{2}(1) = 2$\n",
    "\n",
    "suggestion for 2nd signal $[s_{2_0} = 1]$:   $\\alpha_{2}(0) = 2, \\alpha_{2}(1) = 1$\n",
    "\n",
    "Correlation tensors representing the above functions:\n",
    "\n",
    "$Q^{a_{1_1} [s_{2_0} = 0]}_{a_{2_0}} = \\begin{array}{l|cc}\n",
    " a_{2_0}\\backslash a_{1_1} & 0 & 1  \\\\\n",
    "\\hline    \\quad 0 & 0 & 0 \\\\\n",
    "          \\quad 1 & 1 & 0 \\\\\n",
    "          \\quad 2 & 0 & 1 \\\\\n",
    "        \\end{array}, \\quad Q^{a_{1_1} [s_{2_0} = 1]}_{a_{2_0}} = \\begin{array}{l|cc}\n",
    " a_{2_0}\\backslash a_{1_1} & 0 & 1  \\\\\n",
    "\\hline    \\quad 0 & 0 & 0 \\\\\n",
    "          \\quad 1 & 0 & 1 \\\\\n",
    "          \\quad 2 & 1 & 0 \\\\\n",
    "        \\end{array}$\n",
    "\n",
    "So,\n",
    "\n",
    "$Q^{a_{1_1} s_{2_0}}_{a_{2_0}} = \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} &\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Correlation signal:\n",
    "\n",
    "$\\Gamma_{s_{1_1} s_{2_0} s_{1_1}} = \\begin{array}{l|cc}\n",
    " s_{1_1} s_{2_0} s_{1_1}\\backslash & &   \\\\\n",
    "\\hline    \\quad 000 & \\frac{1}{4} \\\\\n",
    "          \\quad 010 & 0 \\\\\n",
    "          \\quad 101 & 0 \\\\\n",
    "          \\quad 111 & \\frac{1}{4} \\\\\n",
    "          \\quad 000 & \\frac{1}{4} \\\\\n",
    "          \\quad 010 & 0 \\\\\n",
    "          \\quad 101 & 0 \\\\\n",
    "          \\quad 111 & \\frac{1}{4} \n",
    "        \\end{array} = \\begin{bmatrix}\n",
    "\\frac{1}{4} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{4}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "I know you'll have a problem with those signal indices (but my reformulation has worked), so if needed, i'll explain the TRICK in the meeting.\n",
    "\n",
    "[**Notice:** Taking marginal over one $s_{1_1}$ (assigned for $1_1$'s action memory) yeilds $\\Gamma_{s_{2_0} s_{1_1}} = \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{bmatrix}$. In forges example here, $a_{1_1}$ is irrelevant to payoff tensor, and is only used to influence player 2's actions. But I do this to preserve and demonstrate the generality of my aproach. When the payoff tensor depends on player's action and the player can cheap talk to other players, the player then has to take **two** decisions over action set independently; one to execute, and one to cheap talk to. So there must be TWO different sugestion signals for the advice. Here it's just that there's no problem assuming executed is same as cheap talked, as executed is a dummy. So player looks the same signal]\n",
    "\n",
    "So, \n",
    "$$Q_{a_{1_1} a_{2_0}} = Q^{s_{1_1}}_{a_{1_1}} Q^{a_{1_1} s_{2_0}}_{a_{2_0}} Q^{s_{1_1}}_{a_{1_1}} \\Gamma_{s_{1_1} s_{2_0} s_{1_1}} =  \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} \\otimes \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} &\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "\\frac{1}{4} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{4}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\frac{1}{2} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{2} \\\\\n",
    "0\n",
    "\\end{bmatrix}$$ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6eab8-c39d-4fa2-a023-670dfa38c3e5",
   "metadata": {},
   "source": [
    "\n",
    "#### Advice for $(1_0, 2_0)$:\n",
    "\n",
    "$$Q_{a_{1_0}, a_{2_0}} = Q^{}_{a_{1_0}} Q^{a_{1_0} s_{2_0}}_{a_{2_0}} Q^{}_{a_{1_0}} \\Gamma_{s_{1_1} s_{2_0} s_{1_1}} \\mathbf{1}^{s_{1_1} s_{1_1}}$$\n",
    "\n",
    "for agent $1_0$:\n",
    "\n",
    "$Q^{}_{a_{1_1}}  = \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "for agent $2_0$:\n",
    "\n",
    "So here we come to the big point. Agent $2_0$ getting the same advice. Its just that the player 2 doesn't know the cheap talk $a_{1_0}$ is coming from which agent of player 1. \n",
    "\n",
    "$Q^{a_{1_0} s_{2_0}}_{a_{2_0}} = \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} &\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Correlation signal:\n",
    "\n",
    "Since, agent $1_1$ is not activated, $s_{1_1} s_{1_1}$ is dummy. So we gotta take the marginal over it. \n",
    "\n",
    "$\\Gamma_{s_{2_0}} = \\Gamma_{s_{1_1} s_{2_0} s_{1_1}} \\mathbf{1}^{s_{1_1} s_{1_1}} = \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "\\frac{1}{2} \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "So, \n",
    "$$Q_{a_{1_0} a_{2_0}} = Q^{}_{a_{1_0}} Q^{a_{1_0} s_{2_0}}_{a_{2_0}} Q^{}_{a_{1_0}} \\Gamma_{s_{1_1} s_{2_0} s_{1_1}} \\mathbf{1}^{s_{1_1} s_{1_1}} =  \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{bmatrix}\\otimes\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} &\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "\\frac{1}{2} \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "\\frac{1}{4}\n",
    "\\end{bmatrix}$$ \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021aee49-7860-4c59-af16-8a4ecfabb1ed",
   "metadata": {},
   "source": [
    "So finally\n",
    "\n",
    "$Q_{a_{i_{t_i}}} = \\begin{bmatrix}\n",
    "Q_{a_{1_0} a_{2_0}} \\\\ \n",
    "Q_{a_{1_1} a_{2_0}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "\\frac{1}{4}\n",
    "\\end{bmatrix} \\\\\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\frac{1}{2} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{2} \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "By the following transformation\n",
    "$Q_{a_{i_{t_i}}} \\rightarrow Q^t_a = \\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "\\frac{1}{4} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{4} & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "\\frac{1}{4} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{4} & 0\n",
    "\\end{bmatrix}$\n",
    "\n",
    "with lables:\n",
    "\n",
    "$$Q^t_a = \\begin{array}{l|cc}\n",
    " a\\backslash t & 00 & 10  \\\\\n",
    "\\hline    \\quad 00 & 0 & 0  \\\\\n",
    "          \\quad 01 & \\frac{1}{4} & \\frac{1}{2} \\\\\n",
    "          \\quad 02 & \\frac{1}{4} & 0  \\\\\n",
    "          \\quad 10 & 0 & 0  \\\\\n",
    "          \\quad 11 & \\frac{1}{4} & \\frac{1}{2} \\\\\n",
    "          \\quad 12 & \\frac{1}{4} & 0 \n",
    "        \\end{array}$$\n",
    "\n",
    "And there we have the agent form correlation thats not in Local correlation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045b92e-d913-452a-8243-e9d64e4a06b9",
   "metadata": {},
   "source": [
    "So the expected payoff: \n",
    "\n",
    "$\\langle v \\rangle = \\mathbf{1}^a Q^t_a v^t_a P_t = \\begin{bmatrix}\n",
    "1 & 1 & 1 & 1 & 1 & 1\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "\\frac{1}{4} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{4} & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "\\frac{1}{4} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{4} & 0\n",
    "\\end{bmatrix} \\circ \\begin{bmatrix}\n",
    "(6,0) & (0,6) \\\\\n",
    "(0,4) & (6,4) \\\\\n",
    "(4,6) & (4,0) \\\\\n",
    "(6,0) & (0,6) \\\\\n",
    "(0,4) & (6,4) \\\\\n",
    "(4,6) & (4,0) \n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{bmatrix} = (4, 4.5)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2b5bb-09db-4d2a-8049-80ff7a0563d7",
   "metadata": {},
   "source": [
    "## Why the above $Q^t_a$ formed out of agent normal form advice is the same conditional distribution of communication advice given in the Forges?\n",
    "\n",
    "Dont believe me? Ok then take the marginal over $a_1$:\n",
    "\n",
    "$$Q^{t_1}_{a_2} = Q^t_a \\mathbf{1}^{a_1} = Q^{t_1 0}_{a_1, a_2} \\mathbf{1}^{a_1} = \\begin{array}{l|cc}\n",
    " a_2\\backslash t_1 0 & 00 & 10  \\\\\n",
    "\\hline    \\quad 0 & 0 & 0  \\\\\n",
    "          \\quad 1 & \\frac{1}{2} & 1 \\\\\n",
    "          \\quad 2 & \\frac{1}{2} & 0  \n",
    "        \\end{array}$$\n",
    "        \n",
    "This is exactly the communication advice prescribed by forges. So I am it saying again, I strongly contest forges aproach of classifing equilirbria/strategies by payoff profiles!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ed215-38a3-4487-87bb-1c18feca27e1",
   "metadata": {},
   "source": [
    "\n",
    "<!-- and $Q^{t_1 t_1}_{a_{1} a_{1}} = \\begin{bmatrix}\n",
    "Q^{t_1}_{a_{1}}\n",
    "\\end{bmatrix}_{a_{1}}^{t_1} = \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{2} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{2} & \\frac{1}{2}\n",
    "\\end{bmatrix} & \\begin{bmatrix}\n",
    "\\frac{1}{2} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{2} & \\frac{1}{2}\n",
    "\\end{bmatrix} \\\\\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{2} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{2} & \\frac{1}{2}\n",
    "\\end{bmatrix} & \\begin{bmatrix}\n",
    "\\frac{1}{2} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{2} & \\frac{1}{2}\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2022d1-94f0-493f-be10-fff0c9685cad",
   "metadata": {},
   "source": [
    "## Why $Q^t_a$ of this agent normal form advice with cheap talk is not a local correlation.\n",
    "\n",
    "The convex decombosition (determenistic is always sufficiant, as from my property 2 in the side reference notebook):\n",
    "\n",
    "$$ Q^t_a = \\begin{array}{l|cc}\n",
    " a\\backslash t& 00 & 10  \\\\\n",
    "\\hline    \\quad 00 & 0 & 0  \\\\\n",
    "          \\quad 01 & \\frac{1}{4} & \\frac{1}{2} \\\\\n",
    "          \\quad 02 & \\frac{1}{4} & 0  \\\\\n",
    "          \\quad 10 & 0 & 0  \\\\\n",
    "          \\quad 11 & \\frac{1}{4} & \\frac{1}{2} \\\\\n",
    "          \\quad 12 & \\frac{1}{4} & 0 \n",
    "        \\end{array} \\\\ = p_1 \\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "0 &  0 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix} + p_2 \\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "1 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix} + p_3 \\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "0 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "1 &  0 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix} + p_4 \\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "1 & 1 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix} \\\\ + q_1 \\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix} + q_2 \\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "0 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}+ q_3 \\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "0 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "0 &  0 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}+ q_4 \\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 1\\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Where $(p_1, p_2, p_3, p_4, q_1, q_2, q_3, q_4) = (\\frac{1}{8},\\frac{1}{8},\\frac{1}{8},\\frac{1}{8},\\frac{1}{8},\\frac{1}{8},\\frac{1}{8},\\frac{1}{8}) \\text{ or } (\\frac{1}{4},0,0,\\frac{1}{4},\\frac{1}{4},0,0,\\frac{1}{4})$ or any other.\n",
    "\n",
    "- The correlation tensors whose coiffients are $p_i$ are product correlation tensor, and the correlation tensors whose coiffients are $q_i$ are strictly correlated correlation tensors. Thus, half are always strictly correlated correlation tensors. So this distribution is **NOT** Local.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01e8d2-981f-4778-82e8-b5269ff12337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a6fb1-7f4e-4a77-89a0-5a0eb0910917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd686114-7dea-4fd8-92e1-e90a242d41c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf02a2-5cda-4537-afda-806181d53712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850434c-8038-416a-a031-23a1dbc9e3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60053e7e-f4c6-45ba-a231-628ad6ce17e6",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\mathbf{r} \\equiv \\begin{bmatrix}\n",
    "y \\\\\n",
    "\\theta\n",
    "\\end{bmatrix}\n",
    "\\label{eq:vector_ray} \\tag{1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad443b-01a2-4a2d-b5aa-74e7918bcd6d",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "Q_{a_{1_1}, a_{2_0}} =  Q^{s_{1_1}}_{a_{1_1}} Q^{a_{1_1} s_{2_0}}_{a_{2_0}} Q^{s_{1_1}}_{a_{1_1}} \\Gamma_{s_{1_1} s_{2_0} s_{1_1}} \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda586a-a58d-40d8-b9a1-78b97fa2d662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
