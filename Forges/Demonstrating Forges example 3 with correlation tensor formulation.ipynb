{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee89aa2b-56cd-4a4b-b009-e1d346115c65",
   "metadata": {},
   "source": [
    "# Demonstrating Forges example 3 with correlation tensor formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7fb1d-7914-467e-8d45-54f015077aff",
   "metadata": {},
   "source": [
    "## Quick summary on my correlation tensor formulation\n",
    "\n",
    "### Correlation tensor\n",
    "- probabilty vector: $P_t \\leftrightarrow P(t)$\n",
    "- correlation tensor: $Q^t_a  \\leftrightarrow Q(a \\mid t)$\n",
    "- Represents any functions (pure or random) mapping from any input sets to output sets.\n",
    "\n",
    "#### Exploitations:\n",
    "- Tensor notations\n",
    "    - Upper index: input\n",
    "    - Lower index: output\n",
    "- Einstein summation:\n",
    "    - $Q^t_a P_t \\leftrightarrow \\sum_t Q(a \\mid t) P(t)$\n",
    "- Not the standard tensor defined as multilinear map from vector space and its dual.\n",
    "    - Correlation tensors are different object as probablity vectors dont form vector space and there aint analouge for basis to speak about basis transformations. (more details on these thoughts i leave it for another article with my idea of Tensors defined over finite feilds)\n",
    "\n",
    "#### Properties:\n",
    "$\\mathbf{1}$ denotes the all one tensor.\n",
    "\n",
    "1. $0 \\leq Q^t_a\\leq 1$ and $\\mathbf{1}^a Q^t_a = \\mathbf{1}^t $\n",
    "- $Q_a = Q^t_a P_t$\n",
    "\n",
    "Convex combibation:\n",
    "- $Q^t_a = Q^{t \\gamma}_a \\Gamma_{\\gamma}$\n",
    "    - $Q^{t \\gamma}_a$ is a row vector of correlation tensors. And $\\mathbf{1}^{\\gamma} \\Gamma_{\\gamma} = 1$\n",
    "    \n",
    "- More clean properties and definitions still trying to concieve, and cant remember the unwritten thoughts now. I leave it from here for another article for now.\n",
    "\n",
    "Function representation:\n",
    "- $Q^t_a$ represents pure (deterministic) function $g: T \\rightarrow A$ if enries are zeros and one. i.e., $Q^t_a \\in \\{0, 1\\}$ satisfying property 1.\n",
    "    - Example: $T = \\{t^1, t^2\\}, A = \\{a^1, a^2\\}$. The function $g:t \\mapsto a \\mid t \\in T, a \\in A$;   $g(t = t^1) = a^1, g(t = t^2) = a^1$ is represented by $Q^{t}_{a}  = \\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}$\n",
    "\n",
    "- $Q^t_a$ represents a random function if its a convex combination of correlation tensors representing pure functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10243485-6b8b-4734-b358-6820d60f060a",
   "metadata": {},
   "source": [
    "### Definition of the general Game:\n",
    "If the players are $[n]$, the types and actions are $T_i$ and $A_i$ for $i \\in [n]$, then \n",
    "\n",
    "- a game is described a **Payoff Tensor** $$v^t_a \\in \\mathbb{R}^n$$ where $t \\in T = \\times_i T_i$ and $a \\in A = \\times_i A_i$ are type and action profiles.\n",
    "    - The type profile $t$ occurs at $P_t$\n",
    "- a **Strategy Profile** of the game is the correlation tensor $Q^t_a$.\n",
    "- The **expected payoff** profile of the strategy profile $Q^t_a$ is then $$\\langle v \\rangle = \\mathbf{1}^a (Q^t_a\\circ v^t_a) P_t $$  \n",
    "\n",
    "The strategy profile $Q^t_a$ can be formed out of multiple ways; players individual strategies, due to advices (classical or quantum), intercommunication between players (cheap talks), or further complicate it to any other complex ways humans can think of to make life harder. Thus, this is the most general notion of a static game I can think of.\n",
    "\n",
    "- When all $T_i$'s are singletons, the payoff tensor is a vector, then the game beomes game of complete information.\n",
    "\n",
    "#### Equilibrium\n",
    "\n",
    "The strategy profile $Q^t_a$ is an equilibrium if for every possible deviation $Q^t_a \\rightarrow D^{t}_a(i)$ caused by unilateral deviation of each player $i \\in [n]$, \n",
    "\n",
    "$$\\mathbf{1}^a \\big(Q^t_a\\circ v^t_a(i)\\big) P_t \\geq \\mathbf{1}^a \\big(D^t_a(i)\\circ v^t_a(i)\\big) P_t \\quad \\forall i \\in [n]$$\n",
    "\n",
    "where $v^t_a(i)$ is the projection of payoff tensor from $\\mathbb{R}^n$ to player $i$.\n",
    "\n",
    "#### Pareto optimal(attempt)\n",
    "\n",
    "$$\\mathbf{1}^a \\big(Q^t_a\\circ v^t_a\\big) P_t \\geq \\mathbf{1}^a \\big(D^t_a(i)\\circ v^t_a\\big) P_t \\quad \\forall i \\in [n]$$\n",
    "\n",
    "e.i., with the following notation for inequalities of tuples: $(x_i)_i \\geq (y_i)_i \\iff x_i \\geq y_i \\,\\, \\forall i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85c850d-54ed-496e-b66e-be0336a7c582",
   "metadata": {},
   "source": [
    "### The formation of correlation tensor $Q^t_a$\n",
    "\n",
    "#### As from individual player strategies:\n",
    "\n",
    "#### Pure:\n",
    "\n",
    "<!-- player $i$'s: \n",
    " -->\n",
    "Lets denote $Q(A_i^{T_i})$ as the set of all $Q^{t_1}_{a_1}$ that represents each pure function in $A_i^{T_i}$\n",
    "\n",
    "Example: $T_1 = \\{ 0, 1\\}, A_1 = \\{ 0, 1\\}$. Then $Q(A_i^{T_i}) = \\Big\\{ \\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix} \\Big \\}$ \n",
    "\n",
    "complete Pure strategy profile: $Q^t_a = \\bigotimes_i Q^{t_i}_{a_i}$, where $Q^{t_i}_{a_i} \\in Q(A_i^{T_i}) \\,\\, \\forall i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f369fedd-1bc3-443d-800d-2acbd21d0896",
   "metadata": {},
   "source": [
    "#### Mixed\n",
    "An individual mixed strategy is a convex combination of pure strategies. So, $$Q^{t_i}_{a_i} = Q^{t_i \\gamma_i}_{a_i} \\Gamma_{\\gamma_i} \\, , \\quad \\text{where } Q^{t_i (\\gamma_i)}_{a_i} \\in Q(A_i^{T_i}).$$ \n",
    "\n",
    "Notice: $Q^{t_i \\gamma_i}_{a_i}$ is equvalent to the random function $g(t_i, a_i, \\gamma_i)$\n",
    "\n",
    "Example: let $\\gamma_i \\in \\{1,2,3,4\\}$, $\\Gamma_{\\gamma_i} = \\begin{bmatrix}\n",
    "p_1 \\\\\n",
    "p_2\\\\\n",
    "p_3 \\\\\n",
    "p_3\n",
    "\\end{bmatrix}$, and $Q^{t_i \\gamma_i}_{a_i} = \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}& \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}& \\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}& \\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix} \n",
    "\\end{bmatrix}$\n",
    "\n",
    "So, $$Q^{t_i}_{a_i} = Q^{t_i \\gamma_i}_{a_i} \\Gamma_{\\gamma_i} = \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}& \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}& \\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}& \\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix} \n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "p_1 \\\\\n",
    "p_2\\\\\n",
    "p_3 \\\\\n",
    "p_3\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "p_1 + p_2 & p_1 + p_3 \\\\\n",
    "p_3 + p_4 & p_2 + p_4 \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "I denote set of all such mixed strategy tensor that can be formed out of any arbitary $\\Gamma_{\\gamma_i}$ as $Q\\big(\\Delta(A_i^{T_i})\\big)$.\n",
    "\n",
    "complete mixed strategy profile: $Q^t_a = \\bigotimes_i Q^{t_i}_{a_i}$, where $Q^{t_i}_{a_i} \\in Q\\big(\\Delta(A_i^{T_i})\\big) \\,\\, \\forall i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7d61a-2849-42fb-9559-7bb5d69f16dc",
   "metadata": {},
   "source": [
    "#### General mixed strategy:\n",
    "Notice, for the above definition of mixed strategy, each proabibity distribution over $A_i$ for each input in $T_i$ is correlated with each other. A general mixed strategy is any arbitary $Q^{t_i}_{a_i}$. Before I use to define it as a map $\\tilde{g}: T_i \\rightarrow \\Delta A_i$. I denote set of all $Q^{t_i}_{a_i}$ as $Q\\big((\\Delta A_i)^{T_i}\\big)$.\n",
    "\n",
    "Example:\n",
    "$Q^{t_i}_{a_i}  = \\begin{bmatrix}\n",
    "p & q \\\\\n",
    "1-p & 1-q\n",
    "\\end{bmatrix}$\n",
    "\n",
    "So we have, $$Q(A_i^{T_i}) \\subset Q\\big(\\Delta(A_i^{T_i})\\big) \\subset Q\\big((\\Delta A_i)^{T_i}\\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8678959-9041-433b-9622-b7c15284cd21",
   "metadata": {},
   "source": [
    "#### As from following advice:\n",
    "\n",
    "#### Aumman's pure advice:\n",
    "What we have to keep in mind while formulating is that, it should yeild Aumman's correalted strategy while $T_{i}$s are singletons. The advisor recommends pure strategies.\n",
    "\n",
    "So Aumman's correlated strategy should be a joint distribution over pure strategy profiles $Q(A^{T}) = \\times_i Q(A_i^{T_i})$. So, \n",
    "\n",
    "$$Q^t_a = Q^{t s}_{a} \\Gamma_{s} \\, , \\quad \\text{where } Q^{t(s)}_{a} \\in Q(A^{T})$$\n",
    "Expanding: $$Q^t_a = \\bigotimes_i Q^{t_i s_i}_{a_i} \\Gamma_{s_1, s_2, \\dots, s_n} \\, , \\quad \\text{where } Q^{t_i}_{a_i} \\in Q(A_i^{T_i}) \\,\\, \\forall i$$\n",
    "\n",
    "I denote the set of all such $Q^t_a$ formed out of any arbitary $\\Gamma_{s}$ as $Q\\big(\\Delta(A^{T})\\big)$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b21115-7e93-4f53-85d5-28f1160945d6",
   "metadata": {},
   "source": [
    "#### Mixed strategy advice:\n",
    "\n",
    "In game of complete information, recommending mixed strategies is same as recomending a pure strategies from a different distribution. Does this fact hold here as well? Lets check it out!\n",
    "\n",
    "So I denote set of all mixed strategy profiles as $Q\\big(\\Delta^n (A^{T}) \\big) = \\times_i Q \\big(\\Delta(A_i^{T_i})\\big)$ \n",
    "\n",
    "So the correlation tensor now is, $$Q^t_a = Q^{t s}_{a} \\Gamma_{s} \\, , \\quad \\text{where } Q^{t(s)}_{a} \\in Q\\big(\\Delta^n (A^{T}) \\big)$$\n",
    "\n",
    "And I denote the set of all such $Q^t_a$ formed out of any arbitary $\\Gamma_{s}$ as $Q\\Big(\\Delta\\big(\\Delta^n (A^{T})\\big)\\Big)$\n",
    "\n",
    "Now exapanding $$Q^t_a = \\bigotimes_i Q^{t_i s_i}_{a} \\Gamma_{s} = \\bigotimes_i Q^{t_i \\gamma_i s_i}_{a_i} \\Gamma_{\\gamma_i} \\Gamma_{s} \\quad \\text{where } Q^{t_i (\\gamma_i, s_i)}_{a_i} \\in Q(A_i^{T_i})$$\n",
    "\n",
    "$$= Q^{t \\gamma s}_{a} \\Gamma_{\\gamma} \\Gamma_{s} =  Q^{t \\gamma s}_{a} \\Gamma_{\\gamma s} = Q^{t (\\gamma,s)}_{a} \\Gamma_{(\\gamma, s)}$$\n",
    "\n",
    "Now, $Q^{t (\\gamma,s)}_{a} \\in Q(A^{T})$ as $Q^{t_i (\\gamma_i)}_{a_i} \\in Q(A_i^{T_i})$. Thus, we have proved its the same case here as well.\n",
    "\n",
    "So, we have the equevalence $$Q\\Big(\\Delta\\big(\\Delta^n (A^{T})\\big)\\Big) = Q\\big(\\Delta(A^{T})\\big)$$\n",
    "\n",
    "Me: *And there you witness the first power of my correlation tensor formulation!* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da061ec-8d85-43d7-b206-c26363ad316c",
   "metadata": {},
   "source": [
    "#### The General correlated strategy\n",
    "\n",
    "The above equivalence is not true for the general mixed strategy, $Q\\big((\\Delta A_i)^{T_i}\\big) \\setminus  Q\\big(\\Delta(A_i^{T_i})\\big)$,  where $Q^{t_i}_{a_i}$ cannot be decomposed into convex combination of pure strategies. Thus, advice of a general mixed strategy becomes **relavent** in games of incomplete information! \n",
    "\n",
    "So I denote set of all general mixed strategy profiles as $Q\\big((\\Delta^n A)^{T} \\big) = \\times_i Q \\big((\\Delta A_i)^{T_i}\\big)$ \n",
    "\n",
    "So the correlation tensor now is, $$Q^t_a = Q^{t s}_{a} \\Gamma_{s} \\, , \\quad \\text{where } Q^{t(s)}_{a} \\in Q\\big((\\Delta^n A)^{T} \\big)$$\n",
    "\n",
    "And I denote the set of all such $Q^t_a$ formed out of any arbitary $\\Gamma_{s}$ as $Q\\Big(\\Delta\\big((\\Delta^n A)^{T}\\big)\\Big)$. And you may call this as the \"Local correlation\".\n",
    "\n",
    "So we have, $$Q\\Big(\\Delta\\big(\\Delta^n (A^{T})\\big)\\Big) = Q\\big(\\Delta(A^{T})\\big) \\subset Q\\Big(\\Delta\\big((\\Delta^n A)^{T}\\big)\\Big)$$\n",
    "\n",
    "**Finally, there we see the super leap from Aumman's concept in games of complete information!** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd73e4c-e083-4435-9006-8e5847fdc3a4",
   "metadata": {},
   "source": [
    "#### Quantum advice:\n",
    "\n",
    "$$Q^t_a = \\operatorname{Tr} \\rho M^{(t)}_{(a)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6358276c-4084-4a39-aee4-569dc6d4b51d",
   "metadata": {},
   "source": [
    "#### Communicated advice\n",
    "\n",
    "If the advisor takes inputs ($r$) from players to implement distribution over advice, then\n",
    "$$Q^t_a = \\bigotimes_i Q^{s_i}_{a_i} Q^r_s \\bigotimes_i Q^{t_i}_{r_i} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee041d-c855-4fce-b872-5c5dbae9fd9a",
   "metadata": {},
   "source": [
    "### The agent normal form:\n",
    "\n",
    "In Forges, the agents normal form is a conversion of game of incomplete information to complete information like so,\n",
    "$$v^t_a \\longrightarrow v_{t,a} P_t$$\n",
    "\n",
    "**Alternate Interpretation of the same form** \n",
    "\n",
    "The advicer to the boy: *\"I do not wish to know your current **type** of emotion so dont tell me. But, if you are *sad*, then go and have a **nap**. And if you are **happy**, then go and **play in the rain** \"*\n",
    "\n",
    "But, thats just a normal advice of a pure strategy (function mapping from types to actions). And it's **not** an advice of agent normal form!\n",
    "\n",
    "So here's the **correct** advice that mimics this form:\n",
    "\n",
    "The advicer to the boy: *\"So dont tell me your current **type** of emotion. But, if you are *sad*, then go and have a **nap**. And if you are ...\"*\n",
    "\n",
    "Meanwhile the advicer tosses a coin, finds \"Heads\"!. And then,\n",
    "\n",
    "the advicer contineus to the boy: *\"so yeah.. and if you are **happy**, then go and **play in the rain** \"*.\n",
    "\n",
    "Already having been found \"heads\" on the toss,\n",
    "\n",
    "the advicer to Thor (the god of thunder): \"**strike the lightning on the playground!**\"\n",
    "\n",
    "\n",
    "And now this might give you the right idea!... The advicer is the \"decieving Devil\". Ofcourse, the idea of alteranate way of veiwing an advice in a baysian game that is in its agent normal form. And this may or may not be in the  covex combitnation of pure or mixed strategy profiles (function tuples).\n",
    "\n",
    " \n",
    "<!-- - But notice $A_i$ is now an element of the power set of $A_{t_i} = \\{a_{(i, t_i)} | t_i \\in T_i, \\,\\, a_{(i, t_i)} \\in A_i\\}$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cfb661-fb6e-4370-9e6f-2154d3bc78ca",
   "metadata": {},
   "source": [
    "#### Strategy:\n",
    "\n",
    "- I denote an agent to player $i$ as $i_{t_i}$, and  the action of the agent as $a_{i_{t_i}} \\in A_i$.\n",
    "- In agent normal form, the advicer correlates the advice to the active agent of each players. And the active agents from each players $i_{t} = (i_{t_i})_{i} = (1_{t_1}, 2_{t_2}, \\dots, n_{t_n})$ is activated by $P(t)$.\n",
    "    - I denote the active agents action profile as $a_{i_t} = (a_{1_{t_1}}, a_{2_{t_2}}, \\dots, a_{n_{t_n}})$ \n",
    "\n",
    "- As per my interpretation (the alternate view I described above) of Forges, the advicer **do not** know the current active agent profile. However, the adviser has already prepared the joined advices for **each** active agent profiles, and privtely recommends agent actions $a_{i_{t_i}}$ of all agents $i_{t_i}$ of player $i$ to the player $i$, without asking the player $i$ which of it's agent is currently active. \n",
    "    - In this way, the agent **do not** know the current active agent profile $i_{t}$ activated by $P(t)$. So the adviser is still not God and also doesnt gets inputs from players.\n",
    "    - Neigther, the each player know the current active agents of other players than their self's. And as usual the players only knows the distribtion $P$ which they can use to calculate conditional probabilty of other players active agents.\n",
    "    - **Thus the game is still bayesian and played as game of incomplete information**\n",
    "\n",
    "- So the correlation tensor for active agent profile due to advice is as follows:\n",
    "$$Q_{a_{i_t}} = \\bigotimes_{i} Q^{s_{i_{t_i}}}_{a_{i_{t_i}}} \\Gamma_{s_{i_{t}}}$$\n",
    "\n",
    "- As I interpreted above, this form can still be played as game of incomplete informatiom. So we can have this following transformation:\n",
    "$$Q_{a_{i_t}} v_{a_{i_t}} P_t \\longrightarrow Q^t_a v^t_a$$\n",
    "    - This means we can stack up $Q_{a_{i_t}}$'s column wise by $t$ to form the correlation tensor like so: $$Q^t_a = \\begin{bmatrix}Q_{a_{i_t}}\\end{bmatrix}^t$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e19aa5-e100-4f5d-9889-ecff3bedb669",
   "metadata": {},
   "source": [
    "## The forges example 3 game\n",
    "\n",
    "$T_1 = \\{0, 1\\}, T_2 = \\{0\\}$, $P(t) = \\frac{1}{2} \\,\\, \\forall t \\in T$ (uniform), $A_1 = \\{0,1\\}, A_2 = \\{0,1,2\\}$.\n",
    "\n",
    "#### payoff tensor:\n",
    "\n",
    "$v^a_t =$\n",
    "\n",
    "|**a \\ t**|**00**|**10**|\n",
    "|-------|-----|-----|\n",
    "|**00** |(6,0)|(0,6)|\n",
    "|**01** |(0,4)|(6,4)|\n",
    "|**02** |(4,6)|(4,0)|\n",
    "|**10** |(6,0)|(0,6)|\n",
    "|**11** |(0,4)|(6,4)|\n",
    "|**12** |(4,6)|(4,0)|\n",
    "\n",
    "**Notice:** The payoffs are independent of $A_1$ here also.\n",
    "\n",
    "### The game description:\n",
    "- Here, player 1 sends $a_1 \\in A_1$ to player 2.\n",
    "- So, player 2 takes $a_1$ as input.\n",
    "    - Notice there are no other external inputs for player 2 as $T_2$ is singleton.\n",
    "- Since $v^t_a$ is independent of $a_1$, player 1's strategy only is to use it to unfluence player 2's decision on $a_2$, which $v^a_t$ is depndent on.\n",
    "- As player 1 sends $a_1$ based on $t_1$, player 2's strategy is now to choose $a_2$ based on $a_1$, as $v^a_t$ is dependent on $t_1$.\n",
    "\n",
    "#### strategies:\n",
    "\n",
    "so the pure strategy set for player 1 is $A_1^{T_1}$ and for player 2 is $A_2^{A_1}$\n",
    "\n",
    "Individual strategy(mixed or pure) with stochastic tensor notation:\n",
    "\n",
    "player 1: $Q^{t_1}_{a_1 a_1} \\quad$,   player 2: $Q^{a_1}_{a_2}$\n",
    "\n",
    "So $$\\begin{equation}Q^t_a = Q^{t_1,0}_{a_1,a_2} = Q^{t_1}_{a_1 a_1} Q^{a_1}_{a_2}\\end{equation}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185858b-9b8f-4822-9769-9680992b0866",
   "metadata": {},
   "source": [
    "#### Agent normal form:\n",
    "\n",
    "so Agents for player $1$ are: agent $1_0$ and agent $1_1$. \n",
    "\n",
    "Since the $T_2$ is singleton, the active agent profiles is: $i_t = \\{(1_0, 2_0), (1_1, 2_0)\\}$\n",
    "\n",
    "Advice for $(1_1, 2_0)$:\n",
    "\n",
    "$$Q_{a_{1_1}} Q_{a_{2_0}} = Q^{s_{1_1}}_{a_{1_1}} Q^{a_{1_1} s_{2_0}}_{a_{2_0}} Q^{s_{1_1}}_{a_{1_1}} \\Gamma_{s_{1_1} s_{2_0} s_{1_1}}$$\n",
    "\n",
    "for agent $1_1$:\n",
    "\n",
    "$Q^{s_{1_1}}_{a_{1_1}}  = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "for agent $2_0$:\n",
    "\n",
    "$Q^{a_{1_1} s_{2_0}}_{a_{2_0}} = \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} &\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Correlation signal:\n",
    "\n",
    "$\\Gamma_{s_{1_1} s_{2_0} s_{1_1}} = \\begin{bmatrix}\n",
    "\\frac{1}{4} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{4}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "[**Notice:** Taking marginal over one $s_{1_1}$ (assigned for 1_1's action memory) yeilds $\\Gamma_{s_{2_0} s_{1_1}} = \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{bmatrix}$. In forges example here, $a_{1_1}$ is irrelevant to payoff tensor, and is only used to influence player 2's actions. But I do this to preserve and demonstrate the generality of my aproach. When the payoff tensor depends on player's action and the player can cheap talk to other players, the player then has to take **two** decisions over action set independently; one to execute, and one to cheap talk to. Here it's just that there's no problem assuming executed is same as cheap talked, as executed is a dummy.]\n",
    "\n",
    "So, \n",
    "$$Q_{a_{1_1} a_{2_0}} = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} \\otimes \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} &\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "\\frac{1}{4} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{4}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\frac{1}{2} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{2} \\\\\n",
    "0\n",
    "\\end{bmatrix}$$ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6eab8-c39d-4fa2-a023-670dfa38c3e5",
   "metadata": {},
   "source": [
    "\n",
    "Advice for $(1_0, 2_0)$:\n",
    "\n",
    "$$Q_{a_{1_0}} Q_{a_{2_0}} = Q^{}_{a_{1_0}} Q^{a_{1_0} s_{2_0}}_{a_{2_0}} Q^{}_{a_{1_0}} \\Gamma_{s_{1_1} s_{2_0} s_{1_1}} \\mathbf{1}^{s_{1_1} s_{1_1}}$$\n",
    "\n",
    "for agent $1_0$:\n",
    "\n",
    "$Q^{}_{a_{1_1}}  = \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "for agent $2_0$:\n",
    "\n",
    "So here we come to the big point. Agent $2_0$ getting the same advice. Its just that the player 2 doesn't know the cheap talk $a_{1_0}$ is coming from which agent of player 1. \n",
    "\n",
    "$Q^{a_{1_0} s_{2_0}}_{a_{2_0}} = \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} &\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Correlation signal:\n",
    "\n",
    "Since, agent $1_1$ is not activated, $s_{1_1} s_{1_1}$ is dummy. So we gotta take the marginal over it. \n",
    "\n",
    "$\\Gamma_{s_{2_0}} = \\Gamma_{s_{1_1} s_{2_0} s_{1_1}} \\mathbf{1}^{s_{1_1} s_{1_1}} = \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "\\frac{1}{2} \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "So, \n",
    "$$Q_{a_{1_0} a_{2_0}} = \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{bmatrix}\\otimes\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} &\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "\\frac{1}{2} \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "\\frac{1}{4}\n",
    "\\end{bmatrix}$$ \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021aee49-7860-4c59-af16-8a4ecfabb1ed",
   "metadata": {},
   "source": [
    "So finally\n",
    "\n",
    "$Q_{a_{i_{t_i}}} = \\begin{bmatrix}\n",
    "Q_{a_{1_0} a_{2_0}} \\\\ \n",
    "Q_{a_{1_1} a_{2_0}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{4} \\\\\n",
    "\\frac{1}{4}\n",
    "\\end{bmatrix} \\\\\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\frac{1}{2} \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\frac{1}{2} \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "By the following transformation\n",
    "$Q_{a_{i_{t_i}}} \\rightarrow Q^t_a = \\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "\\frac{1}{4} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{4} & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "\\frac{1}{4} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{4} & 0\n",
    "\\end{bmatrix}$\n",
    "\n",
    "And there we have the agent form correlation thats not in Local correlation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045b92e-d913-452a-8243-e9d64e4a06b9",
   "metadata": {},
   "source": [
    "So the expected payoff: \n",
    "\n",
    "$\\langle v \\rangle = \\mathbf{1}^a Q^t_a v^t_a P_t = \\begin{bmatrix}\n",
    "1 & 1 & 1 & 1 & 1 & 1\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "0 & 0\\\\\n",
    "\\frac{1}{4} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{4} & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "\\frac{1}{4} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{4} & 0\n",
    "\\end{bmatrix} \\circ \\begin{bmatrix}\n",
    "(6,0) & (0,6) \\\\\n",
    "(0,4) & (6,4) \\\\\n",
    "(4,6) & (4,0) \\\\\n",
    "(6,0) & (0,6) \\\\\n",
    "(0,4) & (6,4) \\\\\n",
    "(4,6) & (4,0) \n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "\\frac{1}{2} \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{bmatrix} = (4, 4.5)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ed215-38a3-4487-87bb-1c18feca27e1",
   "metadata": {},
   "source": [
    "\n",
    "<!-- and $Q^{t_1 t_1}_{a_{1} a_{1}} = \\begin{bmatrix}\n",
    "Q^{t_1}_{a_{1}}\n",
    "\\end{bmatrix}_{a_{1}}^{t_1} = \\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{2} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{2} & \\frac{1}{2}\n",
    "\\end{bmatrix} & \\begin{bmatrix}\n",
    "\\frac{1}{2} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{2} & \\frac{1}{2}\n",
    "\\end{bmatrix} \\\\\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{2} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{2} & \\frac{1}{2}\n",
    "\\end{bmatrix} & \\begin{bmatrix}\n",
    "\\frac{1}{2} & \\frac{1}{2} \\\\\n",
    "\\frac{1}{2} & \\frac{1}{2}\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f02da2-15cc-4630-a695-a5078efb4138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
